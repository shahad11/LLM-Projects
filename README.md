# LLM-Projects
## Text_to_Image_Generation_using_Stable_Diffusion

In this project, I explored the exciting world of Stable Diffusion by using pre-trained models like Dreamlike Diffusion and Stable Diffusion XL from Hugging Face. I worked with text prompts to generate stunning images and optimized the generation process by leveraging GPU acceleration (CUDA) for efficiency and memory optimization using torch.float16.

Through negative prompting, I guided the model to avoid unwanted elements in the generated images. Additionally, I fine-tuned various parameters such as:

num_inference_steps: Determining the number of denoising steps for higher quality.
height and width: Customizing the resolution of the generated images.
num_images_per_prompt: Generating multiple images for each text prompt.
The code is well-documented and structured to enable users to generate high-quality images easily. The project is perfect for anyone wanting to dive into text-to-image generation and experiment with a flexible and powerful model. All necessary explanations are provided so users with minimal knowledge of deep learning or data science can follow along.

Fork this repository and try it out! Itâ€™s an exciting way to turn text into visuals with minimal setup, allowing you to explore creative outputs in no time.
